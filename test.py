# -*- coding: utf-8 -*-
"""test (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BCgzlnbVQNoJbYzm4ccHbx_no-8ahgqs
"""

import os
import pickle as pk
import random
import numpy as np
import pandas as pd

from scipy import interpolate

import torch
import torch.nn as nn

import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from skopt import gp_minimize
from skopt.space import Real, Integer


def objective(params, x_train, x_test, device, epochs, batch_size, learning_rate):
    target_len, latent_dim  = params
    hidden_dim = 50
    # 插值数据
    x_train_interp = interpolate_data(x_train, int(target_len))
    x_test_interp = interpolate_data(x_test, int(target_len))
    
    # 转换为张量
    x_train_tensor = torch.FloatTensor(x_train_interp).to(device)
    x_test_tensor = torch.FloatTensor(x_test_interp).to(device)
    
    # 创建和训练模型
    model = simpleAE(int(target_len), int(hidden_dim), int(latent_dim)).to(device)
    print(f'target_len={target_len}, latent_dim={latent_dim}, hidden_dim={hidden_dim}')
    # input(f'Number of trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}')
    _, test_losses = train_model(model, x_train_tensor, x_test_tensor, epochs, batch_size, learning_rate)
    
    return test_losses[-1]

def hyperparameter_search_bayesian(x_train, x_test, n_calls=100):
    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
    epochs = 100
    batch_size = 64
    learning_rate = 1e-3

    space = [
        Integer(60, 150, name='target_len'),
        Integer(20, 40, name='latent_dim'),
        # Integer(20, 100, name='hidden_dim')
    ]

    res = gp_minimize(
        lambda params: objective(params, x_train, x_test, device, epochs, batch_size, learning_rate),
        space,
        n_calls=n_calls,
        random_state=0
    )

    return res

def set_random_seed(seed=0):
    np.random.seed(seed)
    torch.manual_seed(seed)
    random.seed(seed)
set_random_seed()

# Construct a simple autoencoder with two layers of encoder and decoder each
class simpleAE(nn.Module):
    def __init__(self, target_len, hidden_dim=50, latent_dim=20):
        super().__init__()
        self.enc = nn.Sequential(
            nn.Linear(target_len, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, latent_dim)
        )
        self.dec = nn.Sequential(
            nn.Linear(latent_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, target_len)
        )

    def forward(self, x):
        z = self.enc(x)
        pred = self.dec(z)
        return pred, z

def interpolate_data(data, target_len):
    itp_dat = []
    for beat in data:
        f = interpolate.interp1d(np.arange(len(beat)), beat)
        itp_beat = f(np.linspace(0, len(beat)-1, target_len))
        itp_dat.append(itp_beat)
    return np.array(itp_dat)

class LSTMAutoencoder(nn.Module):
    def __init__(self, input_dim, hidden_dim, num_layers, latent_dim):
        super().__init__()
        self.input_dim = input_dim
        self.hidden_dim = hidden_dim
        self.num_layers = num_layers
        self.latent_dim = latent_dim
        
        self.encoder = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)
        self.decoder = nn.LSTM(hidden_dim, input_dim, num_layers, batch_first=True)
        
        self.to_latent = nn.Linear(hidden_dim, latent_dim)
        self.from_latent = nn.Linear(latent_dim, hidden_dim)

    def forward(self, x):
        print(f'x: {x.shape}')
        # Encoder
        _, (h, _) = self.encoder(x)
        print(f'h: {h.shape}')
        # Use the last layer's hidden state
        h = h[-1]
        # To latent space
        z = self.to_latent(h)
        print(f'z: {z.shape}')
        # From latent space
        h = self.from_latent(z)
        # Expand h to match batch size
        print(f'h: {h.shape}')
        h = h.unsqueeze(0).repeat(self.num_layers, 1, 1)
        print(f'h: {h.shape}')
        # Decoder
        output, _ = self.decoder(h.transpose(0, 1))
        input(f'output: {output.shape}')
        return output, z
    

def train_model(model, x_train, x_test, epochs, batch_size, learning_rate):
    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
    criterion = nn.MSELoss()
    
    train_losses = []
    test_losses = []
    
    for epoch in range(epochs):
        model.train()
        epoch_loss = 0
        for i in range(0, len(x_train), batch_size):
            batch = x_train[i:i+batch_size]
            optimizer.zero_grad()
            output, _ = model(batch)
            loss = criterion(output, batch)
            loss.backward()
            optimizer.step()
            epoch_loss += loss.item()
        train_losses.append(epoch_loss / (len(x_train) // batch_size))
        
        model.eval()
        with torch.no_grad():
            test_output, _ = model(x_test)
            test_loss = criterion(test_output, x_test)
            test_losses.append(test_loss.item())
        
        if (epoch + 1) % 10 == 0:  # 每10个epoch打印一次
            print(f'Epoch {epoch+1}, Train Loss: {train_losses[-1]:.6f}, Test Loss: {test_losses[-1]:.6f}')
    
    return train_losses, test_losses

# 超參數搜索
def hyperparameter_search(x_train, x_test):

    device = torch.device('cuda:0')
    target_lengths = [60 + i for i in range(40)]
    latent_dims = [20 + i for i in range(20)]
    hidden_dim = 32
    epochs = 100
    batch_size = 64
    learning_rate = 1e-3
    num_layers = 2
    results = {}

    for target_len in target_lengths:
        x_train_interp = interpolate_data(x_train, target_len)
        x_test_interp = interpolate_data(x_test, target_len)
        
        x_train_tensor = torch.FloatTensor(x_train_interp).to(device)
        x_test_tensor = torch.FloatTensor(x_test_interp).to(device)

        for latent_dim in latent_dims:
            print(f"Training with target_len={target_len}, latent_dim={latent_dim}")
            # model = LSTMAutoencoder(target_len, hidden_dim, num_layers, latent_dim).to(device)
            model = simpleAE(target_len, 50, latent_dim).to(device)
            #count trainible params
            input(f'Number of trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}')

            _, test_losses = train_model(model, x_train_tensor, x_test_tensor, epochs, batch_size, learning_rate)
            results[(target_len, latent_dim)] = test_losses[-1]

    return results

def plot_optimization_results(res):
    from skopt.plots import plot_convergence
    plot_convergence(res)
    plt.show()
    #save plots
    import os
    if not os.path.exists('plots'):
        os.makedirs('plots')
    plt.savefig('plots/plot_bayesians_convergence.png')

def main():
    device = torch.device('cuda:0')

    with open('pulse_data.csv', 'r') as file:
        lines = file.readlines()
    raw_dat = []
    for line in lines:
        raw_dat.append([float(x) for x in line.split(',')])

    # # visualization of each beat
    # for i in range(0,10):
    #     plt.figure()
    #     plt.plot(raw_dat[i])

    target_len = 200
    itp_dat = []
    for i in range(len(raw_dat)):
        beat = raw_dat[i]
        f = interpolate.interp1d( np.arange(0, len(beat)), beat)              # create the function for interpolation
        itp_beat = f(np.linspace(0, len(beat)-1, target_len))   # use interpolation function returned by `interp1d`
        itp_dat.append(itp_beat)
    itp_dat= np.array(itp_dat)

    # # visualization of each beat
    # for i in range(0,10):
    #     plt.figure()
    #     plt.plot(itp_dat[i])

    # 分割訓練集和測試集
    train_data, test_data = train_test_split(raw_dat, test_size=0.2, random_state=42)

    # 執行超參數搜索
    # results = hyperparameter_search(train_data, test_data)
    results = hyperparameter_search_bayesian(train_data, test_data, n_calls=50)
    print(f'Best Parameters: {results}')
    plot_optimization_results(results)
    input()
    # 打印結果
    for (target_len, latent_dim), test_loss in results.items():
        print(f"target_len={target_len}, latent_dim={latent_dim}: Test Loss = {test_loss:.6f}")

    # 繪製結果
    plt.figure(figsize=(10, 6))
    for target_len in set(k[0] for k in results.keys()):
        latent_dims = [k[1] for k in results.keys() if k[0] == target_len]
        losses = [results[k] for k in results.keys() if k[0] == target_len]
        plt.plot(latent_dims, losses, marker='o', label=f'target_len={target_len}')

    plt.xlabel('Latent Dimension')
    plt.ylabel('Test Loss')
    plt.title('Test Loss vs Latent Dimension for Different Target Lengths')
    plt.legend()
    plt.grid(True)
    plt.show()


    # simply split train and test
    # ratio = 0.8
    # N = len(itp_dat)
    # ids = np.arange(N)
    # np.random.shuffle(ids)
    # trn_dat = itp_dat[ids[:int(N * ratio)]]
    # tst_dat = itp_dat[ids[int(N * ratio):]]

    # # Normalization
    # trn_mean, trn_std = itp_dat.mean(), itp_dat.std()
    # trn_dat = (trn_dat - trn_mean) / trn_std
    # tst_dat = (tst_dat - trn_mean) / trn_std

    # # put on torch GPU
    # x_trn = torch.from_numpy(trn_dat).to(device).float()
    # x_tst = torch.from_numpy(tst_dat).to(device).float()

    # print(x_trn.shape, x_tst.shape)

    # # initialize model and optimizer
    # batch = 64
    # epochs = 1000
    # learn_rate = 1e-3
    # model = simpleAE(target_len=target_len).to(device)
    # optimizer = torch.optim.Adam(model.parameters(), lr=learn_rate)

    # print(model)

    # for epoch in range(epochs):
    #     # train
    #     trn_losses = []
    #     ids = np.arange(len(x_trn))
    #     np.random.shuffle(ids)
    #     for bi in range(len(x_trn) // batch):
    #         X = x_trn[ids[bi*batch:(bi+1)*batch]]
    #         pred, _ = model(X)
    #         loss = ((pred - X)**2).mean()
    #         trn_losses.append(loss.item())
    #         optimizer.zero_grad()
    #         loss.backward()
    #         optimizer.step()
    #     trn_losses = np.array(trn_losses)

    #     # test
    #     pred, _ = model(x_tst)
    #     tst_losses = ((pred - x_tst)**2).mean(axis=1).detach().cpu().numpy()

    #     print(f'Epoch {epoch}, trn loss: {trn_losses.mean():.6f} tst loss: {tst_losses.mean():.6f}')

    # # visualization
    # pred_np = pred.detach().cpu().numpy()
    # for i in range(0, len(tst_dat), 100):
    #     plt.figure()
    #     plt.plot(pred_np[i])
    #     plt.plot(tst_dat[i])
    #     plt.title(f'ID = {i}')



if __name__ == '__main__':
    main()